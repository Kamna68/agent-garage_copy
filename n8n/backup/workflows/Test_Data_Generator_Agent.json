{
  "name": "Test Data Generator (Agent)",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "test_data_agent",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        860,
        160
      ],
      "id": "webhook-testdata-agent",
      "name": "Webhook",
      "webhookId": "testdata-agent-webhook"
    },
    {
      "parameters": {
        "model": "qwen2:0.5b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        1220,
        380
      ],
      "id": "2ecba473-8192-419f-b588-e79f0f43a711",
      "name": "Ollama Chat Model",
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('Webhook').item.json.body.sessionId }}"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        1440,
        380
      ],
      "id": "17d13940-325f-42ad-9b62-9a094c5ce76e",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        1760,
        160
      ],
      "id": "d401a165-e52b-4bee-82a8-1d75c9b3e7e4",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "content": "## \ud83d\udc46\nThe memory keeps a history of previous messages, allowing for an ongoing conversation with the AI, rather than every interaction starting fresh.\n\n\nThis short term memory stores a customizable length of chat history for the current session.",
        "height": 340,
        "width": 170
      },
      "id": "5e325367-54b6-46df-aba2-b96b82f041a5",
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1420,
        520
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## \ud83d\udc46\nThe Ollama Chat Model node allows to use Large Language Models (LLMs) with conversational agents.\n\nThe LLM llama3.2 is used here.\n",
        "height": 340,
        "width": 170
      },
      "id": "3eb9ad8b-7421-4a37-9b24-9b9710103c5d",
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1180,
        520
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## \ud83d\udc46\n The Webhook node is used to create webhooks, which can receive data from apps and services when an event occurs. It's a trigger node, which means it can start an n8n workflow. In this case it allows Open WebUI  to connect to n8n and run a workflow. \n\nTherefore, the workflow is started as soon as a chat message is sent from Open Webui.",
        "height": 540,
        "width": 170
      },
      "id": "67582f1c-de4e-4598-b14b-b1f177d67393",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        820,
        320
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## \ud83d\udc46\nUse the Respond to Webhook node to control the response to incoming webhooks. This node works with the Webhook node.\n\nIn this case, the generated response from the AI-Agent is sent to Open WebUI via this node.",
        "height": 540,
        "width": 170
      },
      "id": "9afa19d7-be94-4b45-9118-2b26987bc8eb",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1740,
        320
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "# AI-Agents\nAn AI-Agent is an autonomous system that receives data, makes rational decisions, and acts within its environment to achieve specific goals.\n\n### AI agents can be characterised by three components: ###\n\n* Memory Capacities \n* Tools \n* LLM \n\n\n* An LLM acts as the reasoning engine behind the agent and decides what actions to take and in which order. \n\n* Moreover the Agent can use external tools and APIs to perform actions and retrieve information. It can understand the capabilities of different tools and determine which tool to use depending on the task.\n\n\n## Customization of agents\n\n* AI-Agents in n8n can be easily customized using system prompts.\nA system prompt defines the agent\u2019s role, behavior, and area of expertise\u2014whether it's acting as a writer, analyst, advisor, or something else.\n\n* In this case, the AI-Agent has been configured specifically to generate user stories. It analyzes requirements and produces complete user stories in the classic format, including acceptance criteria.\n\n* The agent's purpose can be changed at any time: \nBy simply adjusting the system prompt, it can be reconfigured for virtually any task\u2014such as writing marketing content or drafting support replies.",
        "height": 760,
        "width": 520
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        140,
        80
      ],
      "typeVersion": 1,
      "id": "04adaa41-5c22-4496-91c4-4d740886ce8d",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "content": "## 1. Receiving the user's chat input from Open WebUI",
        "height": 240,
        "width": 340,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        760,
        60
      ],
      "typeVersion": 1,
      "id": "e79fa2f9-9e28-4966-a463-46dab0f2c6d1",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "",
        "height": 900,
        "width": 2660,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        60,
        0
      ],
      "typeVersion": 1,
      "id": "a5cba250-6d3d-4bf2-8767-aeb90ebaa811",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "## 2. Generating Response",
        "height": 240,
        "width": 340,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1200,
        60
      ],
      "typeVersion": 1,
      "id": "e453e16f-286f-4f29-b956-57393fd40d1f",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "content": "## 3. Sending Response to Open WebUI",
        "height": 240,
        "width": 340,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1620,
        60
      ],
      "typeVersion": 1,
      "id": "c5546fbd-985e-4c3a-9db1-8585938a0ab7",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "content": "# Description of the workflow\n\nThe workflow enables users to enter a request via chat in Open WebUI, from which a complete user story is automatically generated. A specialised AI-Agent in n8n takes over the analysis and formulation - the result is displayed directly in the chat.\n\n\n### 1. Receipt of the user request:\n* A user sends a chat message via Open WebUI with the intention of having a user story created. This request automatically starts the n8n workflow.\n* The message is transmitted to n8n - it contains, for example, an idea, requirement or description from which a user story is to be generated.\n\n\n### 2. Processing by AI agent:\n* The message is forwarded to a specially configured AI Agent Node.\n* This agent is designed to create a complete user story from the perspective of a business analyst.\n* The AI-Agent analyses the input and formulates a structured user story in the classic format (\u2018As a [role], I would like [...] to [...]\u2019).\n\n### 3. Generation of the user story:\n* The generated story is sent back to OpenWebUI and displayed to the user directly in the chat window as a response",
        "height": 760,
        "width": 520
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2080,
        60
      ],
      "typeVersion": 1,
      "id": "c6a37041-36db-4331-af9f-e5a5fd7dba84",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Webhook').item.json.body.message || $('Webhook').item.json.body.schema }}",
        "options": {
          "systemMessage": "You are an expert QA engineer and test data generator.\n\nGenerate realistic test data based on the user's request.\n\n**INSTRUCTIONS:**\n1. Understand the schema/fields requested\n2. Generate the specified number of records (user specifies or default 5)\n3. Make data realistic with variety - different names, realistic emails, varied ages/values\n4. Always output valid JSON format\n5. Include edge cases when helpful\n\n**OUTPUT FORMAT:**\n```json\n{\n  \"data\": [\n    {\"id\": 1, \"name\": \"Sarah Johnson\", \"email\": \"sarah.j@techcorp.com\", \"age\": 28, \"status\": \"active\"},\n    {\"id\": 2, \"name\": \"Mike Chen\", \"email\": \"mchen@startup.io\", \"age\": 34, \"status\": \"active\"},\n    {\"id\": 3, \"name\": \"Emma Davis\", \"email\": \"e.davis@company.com\", \"age\": 42, \"status\": \"inactive\"}\n  ],\n  \"record_count\": 3,\n  \"generated_at\": \"2025-11-19T10:30:00Z\"\n}\n```\n\n**QUALITY RULES:**\n- Use realistic names (diverse, not \"User1\", \"User2\")\n- Make emails match names (sarah.j@domain.com)\n- Vary all values - don't repeat patterns\n- Include realistic dates, amounts, statuses\n- Add metadata (count, timestamp) when useful\n\nGenerate creative, production-quality test data now!"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        1240,
        160
      ],
      "id": "agent-testdata",
      "name": "Test Data Agent"
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Test Data Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Test Data Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "Test Data Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Test Data Agent": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "4f06b34c-6057-4cec-a830-ba55400869b8",
  "meta": {
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a"
  },
  "id": "V4Ij2EuIHhjLeXAR",
  "tags": []
}